{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSA Chapter 2: Model Selection with AIC and BIC\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/QuantLet/TSA/blob/main/TSA_ch2/TSA_ch2_model_selection/TSA_ch2_model_selection.ipynb)\n",
    "\n",
    "This notebook demonstrates:\n",
    "- AIC and BIC information criteria for ARMA model selection\n",
    "- Comparison of 9 candidate models fitted to ARMA(1,1) data, complexity vs fit trade-off"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!pip install matplotlib numpy scipy statsmodels pandas -q"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from matplotlib.patches import Polygon\n",
    "# Style configuration\n",
    "COLORS = {\n",
    "    'blue': '#1A3A6E',\n",
    "    'red': '#DC3545',\n",
    "    'green': '#2E7D32',\n",
    "    'orange': '#E67E22',\n",
    "    'gray': '#666666',\n",
    "    'purple': '#8E44AD',\n",
    "}\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'axes.facecolor': 'none',\n",
    "    'figure.facecolor': 'none',\n",
    "    'savefig.transparent': True,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "    'axes.grid': False,\n",
    "    'font.size': 9,\n",
    "    'axes.titlesize': 10,\n",
    "    'axes.labelsize': 9,\n",
    "    'xtick.labelsize': 8,\n",
    "    'ytick.labelsize': 8,\n",
    "    'legend.fontsize': 8,\n",
    "    'figure.dpi': 150,\n",
    "    'lines.linewidth': 1.2,\n",
    "    'axes.edgecolor': '#333333',\n",
    "    'axes.linewidth': 0.8,\n",
    "})\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def save_chart(fig, name):\n",
    "    \"\"\"Save chart as PDF and PNG.\"\"\"\n",
    "    fig.savefig(f'{name}.pdf', bbox_inches='tight', transparent=True, dpi=150)\n",
    "    fig.savefig(f'{name}.png', bbox_inches='tight', transparent=True, dpi=150)\n",
    "    print(f'Saved: {name}.pdf + .png')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set random seed\n",
    "\n",
    "n = 300\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SELECTION: AIC AND BIC\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "Information Criteria:\n",
    "\n",
    "AIC = -2 ln(L\u0302) + 2k\n",
    "BIC = -2 ln(L\u0302) + k ln(n)\n",
    "\n",
    "Where:\n",
    "  L\u0302 = maximized likelihood\n",
    "  k = number of parameters\n",
    "  n = sample size\n",
    "\n",
    "Key Differences:\n",
    "  - AIC: penalizes complexity less \u2192 larger models\n",
    "  - BIC: penalizes complexity more \u2192 more parsimonious models\n",
    "  - BIC penalty grows with n \u2192 increasingly favors simpler models\n",
    "\n",
    "Rule: LOWER is BETTER\n",
    "\"\"\")\n",
    "\n",
    "# Generate true ARMA(1,1) data\n",
    "phi_true = 0.7\n",
    "theta_true = 0.4\n",
    "ar = np.array([1, -phi_true])\n",
    "ma = np.array([1, theta_true])\n",
    "arma_process = ArmaProcess(ar, ma)\n",
    "data = arma_process.generate_sample(nsample=n)\n",
    "\n",
    "# Fit various models and compare\n",
    "models = [\n",
    "    (1, 0, 'AR(1)'),\n",
    "    (2, 0, 'AR(2)'),\n",
    "    (3, 0, 'AR(3)'),\n",
    "    (0, 1, 'MA(1)'),\n",
    "    (0, 2, 'MA(2)'),\n",
    "    (1, 1, 'ARMA(1,1)'),\n",
    "    (2, 1, 'ARMA(2,1)'),\n",
    "    (1, 2, 'ARMA(1,2)'),\n",
    "    (2, 2, 'ARMA(2,2)')\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FITTING MULTIPLE MODELS TO ARMA(1,1) DATA\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True model: ARMA(1,1) with \u03c6={phi_true}, \u03b8={theta_true}\")\n",
    "print(f\"Sample size: n = {n}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Model':<12} {'k':>5} {'Log-Like':>12} {'AIC':>10} {'BIC':>10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for p, q, name in models:\n",
    "    try:\n",
    "        model = ARIMA(data, order=(p, 0, q))\n",
    "        fit = model.fit()\n",
    "        k = p + q + 1  # AR + MA + variance\n",
    "        results.append({\n",
    "            'Model': name,\n",
    "            'p': p,\n",
    "            'q': q,\n",
    "            'k': k,\n",
    "            'LogLike': fit.llf,\n",
    "            'AIC': fit.aic,\n",
    "            'BIC': fit.bic\n",
    "        })\n",
    "        print(f\"{name:<12} {k:>5} {fit.llf:>12.2f} {fit.aic:>10.2f} {fit.bic:>10.2f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name:<12} -- fitting failed\")\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Find best models\n",
    "best_aic = df.loc[df['AIC'].idxmin()]\n",
    "best_bic = df.loc[df['BIC'].idxmin()]\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nBest by AIC: {best_aic['Model']} (AIC = {best_aic['AIC']:.2f})\")\n",
    "print(f\"Best by BIC: {best_bic['Model']} (BIC = {best_bic['BIC']:.2f})\")\n",
    "\n",
    "# Visualization"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# AIC comparison\n",
    "ax1 = axes[0]\n",
    "colors = ['green' if m == best_aic['Model'] else 'blue' for m in df['Model']]\n",
    "ax1.barh(df['Model'], df['AIC'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.axvline(x=best_aic['AIC'], color='green', linestyle='--', linewidth=2)\n",
    "ax1.set_xlabel('AIC (lower is better)')\n",
    "ax1.set_title('AIC Comparison')\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# BIC comparison\n",
    "ax2 = axes[1]\n",
    "colors = ['green' if m == best_bic['Model'] else 'blue' for m in df['Model']]\n",
    "ax2.barh(df['Model'], df['BIC'], color=colors, alpha=0.7, edgecolor='black')\n",
    "ax2.axvline(x=best_bic['BIC'], color='green', linestyle='--', linewidth=2)\n",
    "ax2.set_xlabel('BIC (lower is better)')\n",
    "ax2.set_title('BIC Comparison')\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Parameter count vs fit\n",
    "ax3 = axes[2]\n",
    "ax3.scatter(df['k'], df['AIC'], s=100, label='AIC', alpha=0.7)\n",
    "ax3.scatter(df['k'], df['BIC'], s=100, marker='s', label='BIC', alpha=0.7)\n",
    "for _, row in df.iterrows():\n",
    "    ax3.annotate(row['Model'], (row['k'], row['AIC']), xytext=(5, 5),\n",
    "                 textcoords='offset points', fontsize=8)\n",
    "ax3.set_xlabel('Number of Parameters (k)')\n",
    "ax3.set_ylabel('Information Criterion')\n",
    "ax3.set_title('Complexity vs Fit Trade-off')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_chart(fig, 'ch2_model_selection')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL SELECTION GUIDELINES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "1. Start with ACF/PACF to get initial p, q estimates\n",
    "2. Fit candidate models (vary p and q around initial guess)\n",
    "3. Compare using AIC and BIC\n",
    "4. Check residual diagnostics (Ljung-Box test)\n",
    "5. Use out-of-sample validation if possible\n",
    "\n",
    "When AIC and BIC Disagree:\n",
    "  - AIC tends to select larger models\n",
    "  - BIC tends to select smaller models\n",
    "  - BIC is consistent (selects true model as n \u2192 \u221e)\n",
    "  - AIC is asymptotically efficient (best predictions)\n",
    "\n",
    "Practical Advice:\n",
    "  - Use BIC for model interpretation\n",
    "  - Use AIC for forecasting\n",
    "  - Consider both and check residuals\n",
    "\"\"\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}